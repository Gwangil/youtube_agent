# GPU 기반 처리 서비스 (Whisper Large-v3 + BGE-M3)
# 사용: docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up -d

services:
  # Whisper STT Server (GPU 필수)
  whisper-server:
    build:
      context: .
      dockerfile: services/data-processor/Dockerfile
    container_name: youtube_whisper_server
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - WHISPER_MODEL_DIR=/app/models/whisper
      - WHISPER_MODEL=large-v3
    ports:
      - "8082:8082"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/health"]
      interval: 30s
      timeout: 10s
      start_period: 300s
      retries: 10
    volumes:
      - ./src:/app/src
      - ./shared:/app/shared
      - ./services/data-processor:/app/services/data-processor
      - ./data:/app/data
      - ./models:/app/models
      - /tmp:/tmp
    command: sh -c "python /app/services/data-processor/init_whisper_cache.py && python /app/services/data-processor/whisper_server.py"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - youtube_network

  # BGE-M3 Embedding Server (GPU 권장)
  embedding-server:
    build:
      context: .
      dockerfile: services/data-processor/Dockerfile
    container_name: youtube_embedding_server
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - EMBEDDING_SERVER_PORT=8083
      - CUDA_VISIBLE_DEVICES=0
      - EMBEDDING_MODEL=BGE-M3
    ports:
      - "8083:8083"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/health"]
      interval: 30s
      timeout: 10s
      start_period: 120s
      retries: 10
    volumes:
      - ./src:/app/src
      - ./shared:/app/shared
      - ./services/data-processor:/app/services/data-processor
      - ./models:/app/models
    command: python /app/services/data-processor/embedding_server.py
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - youtube_network

  # Data Processing Service (GPU 모드)
  data-processor:
    build:
      context: .
      dockerfile: services/data-processor/Dockerfile
    container_name: youtube_data_processor
    environment:
      - DATABASE_URL=postgresql://youtube_user:youtube_pass@postgres:5432/youtube_agent
      - REDIS_URL=redis://redis:6379
      - QDRANT_URL=http://qdrant:6333
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - WHISPER_SERVER_URL=http://whisper-server:8082
      - EMBEDDING_SERVER_URL=http://embedding-server:8083
      - PROCESSING_MODE=GPU
    volumes:
      - ./data:/app/data
      - ./src:/app/src
      - ./shared:/app/shared
      - ./services/data-processor:/app/services/data-processor
    command: python /app/services/data-processor/app.py
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_started
      whisper-server:
        condition: service_healthy
      embedding-server:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - youtube_network

  # STT Workers (GPU 모드)
  stt-worker-1:
    build:
      context: .
      dockerfile: services/data-processor/Dockerfile
    container_name: youtube_stt_worker_1_gpu
    environment:
      - DATABASE_URL=postgresql://youtube_user:youtube_pass@postgres:5432/youtube_agent
      - WHISPER_SERVER_URL=http://whisper-server:8082
      - STT_WORKER_ID=0
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379
      - STT_COST_API_URL=http://stt-cost-api:8084
      - PROCESSING_MODE=GPU
      - FORCE_GPU_MODE=true
    volumes:
      - ./src:/app/src
      - ./shared:/app/shared
      - ./services/data-processor:/app/services/data-processor
      - ./data:/app/data
      - /tmp:/tmp
    command: sh -c "/app/services/data-processor/wait_for_whisper.sh && python /app/services/data-processor/stt_worker.py"
    depends_on:
      postgres:
        condition: service_healthy
      whisper-server:
        condition: service_healthy
      stt-cost-api:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - youtube_network

  stt-worker-2:
    build:
      context: .
      dockerfile: services/data-processor/Dockerfile
    container_name: youtube_stt_worker_2_gpu
    environment:
      - DATABASE_URL=postgresql://youtube_user:youtube_pass@postgres:5432/youtube_agent
      - WHISPER_SERVER_URL=http://whisper-server:8082
      - STT_WORKER_ID=1
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379
      - STT_COST_API_URL=http://stt-cost-api:8084
      - PROCESSING_MODE=GPU
      - FORCE_GPU_MODE=true
    volumes:
      - ./src:/app/src
      - ./shared:/app/shared
      - ./services/data-processor:/app/services/data-processor
      - ./data:/app/data
      - /tmp:/tmp
    command: sh -c "sleep 5 && /app/services/data-processor/wait_for_whisper.sh && python /app/services/data-processor/stt_worker.py"
    depends_on:
      postgres:
        condition: service_healthy
      whisper-server:
        condition: service_healthy
      stt-cost-api:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - youtube_network

  stt-worker-3:
    build:
      context: .
      dockerfile: services/data-processor/Dockerfile
    container_name: youtube_stt_worker_3_gpu
    environment:
      - DATABASE_URL=postgresql://youtube_user:youtube_pass@postgres:5432/youtube_agent
      - WHISPER_SERVER_URL=http://whisper-server:8082
      - STT_WORKER_ID=2
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379
      - STT_COST_API_URL=http://stt-cost-api:8084
      - PROCESSING_MODE=GPU
      - FORCE_GPU_MODE=true
    volumes:
      - ./src:/app/src
      - ./shared:/app/shared
      - ./services/data-processor:/app/services/data-processor
      - ./data:/app/data
      - /tmp:/tmp
    command: sh -c "sleep 10 && /app/services/data-processor/wait_for_whisper.sh && python /app/services/data-processor/stt_worker.py"
    depends_on:
      postgres:
        condition: service_healthy
      whisper-server:
        condition: service_healthy
      stt-cost-api:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - youtube_network

  # Vectorization Workers (공통)
  vectorize-worker-1:
    build:
      context: .
      dockerfile: services/data-processor/Dockerfile
    container_name: youtube_vectorize_worker_1
    environment:
      - DATABASE_URL=postgresql://youtube_user:youtube_pass@postgres:5432/youtube_agent
      - QDRANT_URL=http://qdrant:6333
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - EMBEDDING_SERVER_URL=http://embedding-server:8083
      - VECTORIZE_WORKER_ID=0
      - TOTAL_VECTORIZE_WORKERS=3
    volumes:
      - ./src:/app/src
      - ./shared:/app/shared
      - ./services/data-processor:/app/services/data-processor
    command: python /app/services/data-processor/vectorize_worker.py
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_started
      embedding-server:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - youtube_network

  vectorize-worker-2:
    build:
      context: .
      dockerfile: services/data-processor/Dockerfile
    container_name: youtube_vectorize_worker_2
    environment:
      - DATABASE_URL=postgresql://youtube_user:youtube_pass@postgres:5432/youtube_agent
      - QDRANT_URL=http://qdrant:6333
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - EMBEDDING_SERVER_URL=http://embedding-server:8083
      - VECTORIZE_WORKER_ID=1
      - TOTAL_VECTORIZE_WORKERS=3
    volumes:
      - ./src:/app/src
      - ./shared:/app/shared
      - ./services/data-processor:/app/services/data-processor
    command: python /app/services/data-processor/vectorize_worker.py
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_started
      embedding-server:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - youtube_network

  vectorize-worker-3:
    build:
      context: .
      dockerfile: services/data-processor/Dockerfile
    container_name: youtube_vectorize_worker_3
    environment:
      - DATABASE_URL=postgresql://youtube_user:youtube_pass@postgres:5432/youtube_agent
      - QDRANT_URL=http://qdrant:6333
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - EMBEDDING_SERVER_URL=http://embedding-server:8083
      - VECTORIZE_WORKER_ID=2
      - TOTAL_VECTORIZE_WORKERS=3
    volumes:
      - ./src:/app/src
      - ./shared:/app/shared
      - ./services/data-processor:/app/services/data-processor
    command: python /app/services/data-processor/vectorize_worker.py
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_started
      embedding-server:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - youtube_network

networks:
  youtube_network:
    external: true