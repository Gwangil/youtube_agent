"""
LangGraph ê¸°ë°˜ RAG ì—ì´ì „íŠ¸
YouTube ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì§€ëŠ¥í˜• ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ
"""

import os
from typing import List, Dict, Any, TypedDict, Annotated
from operator import add
from langchain_openai import ChatOpenAI
from langchain.schema import Document
from langchain.prompts import ChatPromptTemplate
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage
import json
import sys


class AgentState(TypedDict):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ì •ì˜"""
    messages: Annotated[List[BaseMessage], add_messages]
    query: str
    search_results: List[Dict]
    context: str
    answer: str
    metadata: Dict[str, Any]


class YouTubeRAGAgent:
    """YouTube RAG ì—ì´ì „íŠ¸"""

    def __init__(self):
        # LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-4-turbo-preview",
            temperature=0.1,
            openai_api_key=os.getenv('OPENAI_API_KEY')
        )

        # BGE-M3 ì„ë² ë”© ì„œë²„ URL
        self.embedding_server_url = os.getenv('EMBEDDING_SERVER_URL', 'http://embedding-server:8083')

        # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        qdrant_url = os.getenv('QDRANT_URL', 'http://localhost:6333')
        self.qdrant_client = QdrantClient(url=qdrant_url)

        # ê·¸ë˜í”„ êµ¬ì„±
        self.graph = self._build_graph()

    def _get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """BGE-M3 ì„ë² ë”© ì„œë²„ì—ì„œ ë²¡í„° ìƒì„±"""
        import requests
        try:
            response = requests.post(
                f"{self.embedding_server_url}/embed",
                json={"texts": texts},
                timeout=30
            )
            if response.status_code == 200:
                return response.json()['embeddings']
            else:
                raise Exception(f"ì„ë² ë”© ì„œë²„ ì˜¤ë¥˜: {response.status_code}")
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def _build_graph(self) -> StateGraph:
        """LangGraph êµ¬ì„±"""
        workflow = StateGraph(AgentState)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("search", self._search_node)
        workflow.add_node("generate", self._generate_node)
        workflow.add_node("refine", self._refine_node)

        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("search")
        workflow.add_edge("search", "generate")
        workflow.add_edge("generate", "refine")
        workflow.add_edge("refine", END)

        return workflow.compile()

    def _search_node(self, state: AgentState) -> AgentState:
        """ë‹¤ì¸µ ë²¡í„° ê²€ìƒ‰ ë…¸ë“œ"""
        query = state["query"]
        print(f"[Search] Query: {query}", file=sys.stderr)

        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (BGE-M3 ì‚¬ìš©)
        try:
            query_embedding = self._get_embeddings([query])[0]
            print(f"[Search] Embedding dimension: {len(query_embedding)}", file=sys.stderr)
        except Exception as e:
            print(f"[Search] Embedding error: {e}", file=sys.stderr)
            raise

        all_results = []

        # 1. ìš”ì•½ ê²€ìƒ‰ (ì „ì²´ ì˜ìƒ ì´í•´)
        try:
            summary_results = self.qdrant_client.search(
                collection_name="youtube_summaries",
                query_vector=query_embedding,
                limit=3,
                score_threshold=0.5  # BGE-M3ì— ë§ëŠ” threshold
            )
            print(f"[Search] Summary results: {len(summary_results)}")
            for result in summary_results:
                print(f"  - Score: {result.score:.4f}, Title: {result.payload.get('title', 'N/A')}")
                result.payload['search_type'] = 'summary'
                all_results.append(result)
        except Exception as e:
            print(f"[Search] Summary search error: {e}")
            import traceback
            traceback.print_exc()
            pass  # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ë¬´ì‹œ

        # 2. ë¬¸ë‹¨ ê²€ìƒ‰ (ì¤‘ê°„ ë‹¨ìœ„ ì»¨í…ìŠ¤íŠ¸)
        try:
            paragraph_results = self.qdrant_client.search(
                collection_name="youtube_paragraphs",
                query_vector=query_embedding,
                limit=5,
                score_threshold=0.5
            )
            for result in paragraph_results:
                result.payload['search_type'] = 'paragraph'
                all_results.append(result)
        except Exception as e:
            print(f"[Search] Paragraph search error: {e}", file=sys.stderr)
            pass

        # 3. ì„¸ë°€í•œ ì²­í¬ ê²€ìƒ‰ (ê¸°ì¡´ ë°©ì‹)
        chunk_results = self.qdrant_client.search(
            collection_name="youtube_content",
            query_vector=query_embedding,
            limit=5,
            score_threshold=0.5
        )
        for result in chunk_results:
            result.payload['search_type'] = 'chunk'
            all_results.append(result)

        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 10ê°œ ì„ íƒ
        search_results = sorted(all_results, key=lambda x: x.score, reverse=True)[:10]

        # ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        processed_results = []
        for result in search_results:
            payload = result.payload

            # search_typeì— ë”°ë¼ ë‹¤ë¥¸ í•„ë“œ ì‚¬ìš©
            search_type = payload.get('search_type', 'chunk')
            if search_type == 'summary':
                content_text = payload.get('summary', payload.get('text', ''))
            elif search_type == 'paragraph':
                content_text = payload.get('paragraph', payload.get('text', ''))
            else:
                content_text = payload.get('text', '')

            # ë””ë²„ê¹… ë¡œê·¸
            print(f"[Process] Type: {search_type}, Score: {result.score:.4f}, Title: {payload.get('title', 'N/A')[:50]}...", file=sys.stderr)
            print(f"[Process] Content length: {len(content_text)}", file=sys.stderr)

            processed_results.append({
                'id': result.id,
                'score': result.score,
                'content': content_text,
                'title': payload.get('title', ''),
                'url': payload.get('url', ''),
                'timestamp_url': payload.get('timestamp_url', ''),  # íƒ€ì„ìŠ¤íƒ¬í”„ URL ì¶”ê°€
                'start_time': payload.get('start_time'),  # ì‹œì‘ ì‹œê°„ ì¶”ê°€
                'end_time': payload.get('end_time'),  # ì¢…ë£Œ ì‹œê°„ ì¶”ê°€
                'platform': payload.get('platform', ''),
                'publish_date': payload.get('publish_date', ''),
                'search_type': search_type,
                'metadata': payload
            })

        state["search_results"] = processed_results

        # ê²€ìƒ‰ëœ ë‚´ìš©ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•© (URL ì •ë³´ í¬í•¨)
        context_parts = []
        for i, result in enumerate(processed_results):
            content = result['content']

            # ì»¨í…ì¸ ê°€ ë¹„ì–´ìˆìœ¼ë©´ ìŠ¤í‚µ
            if not content:
                print(f"[Context] Skipping empty content for: {result['title']}", file=sys.stderr)
                continue

            # search_typeì— ë”°ë¼ ë‹¤ë¥¸ ê¸¸ì´ ì œí•œ
            if result.get('search_type') == 'summary':
                max_length = 300  # ìš”ì•½ì€ ë” ê¸¸ê²Œ
            else:
                max_length = 200

            if len(content) > max_length:
                content = content[:max_length] + "..."

            # íƒ€ì„ìŠ¤íƒ¬í”„ URLì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì¼ë°˜ URL
            url_to_use = result.get('timestamp_url', result.get('url', ''))

            # ì‹œê°„ ì •ë³´ ì¶”ê°€
            time_info = ""
            if 'start_time' in result and result['start_time'] is not None:
                minutes = int(result['start_time']) // 60
                seconds = int(result['start_time']) % 60
                time_info = f" [{minutes}:{seconds:02d}]"

            context_parts.append(
                f"[{i+1}. {result['title']}]{time_info}\n{content}\nURL: {url_to_use}\nì ìˆ˜: {result['score']:.3f}"
            )

            print(f"[Context] Added #{i+1}: {result['title'][:30]}... (score: {result['score']:.3f})", file=sys.stderr)

        state["context"] = "\n\n---\n\n".join(context_parts)
        return state

    def _generate_node(self, state: AgentState) -> AgentState:
        """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
        query = state["query"]
        context = state["context"]

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ YouTube ì½˜í…ì¸  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ YouTube ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ë‹µë³€ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•˜ì„¸ìš”:
1. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ë‹µë³€ì— ê´€ë ¨ YouTube ë™ì˜ìƒ ì œëª©ê³¼ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
3. ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ì‹¤ì œ URLì„ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆì‹œ URLì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”)
4. ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
5. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
6. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ê·¸ë ‡ê²Œ ë§í•˜ì„¸ìš”

ë‹µë³€ í›„ì—ëŠ” **ì°¸ê³  ìë£Œ** ì„¹ì…˜ì„ ì¶”ê°€í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ì‹¤ì œ YouTube URLë“¤ì„ ì œê³µí•˜ì„¸ìš”.
ì ˆëŒ€ ì˜ˆì‹œ URL(https://www.youtube.com/watch?v=example)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}
            """),
            ("human", "{query}")
        ])

        # ë‹µë³€ ìƒì„±
        chain = prompt | self.llm
        response = chain.invoke({
            "query": query,
            "context": context
        })

        state["answer"] = response.content
        return state

    def _refine_node(self, state: AgentState) -> AgentState:
        """ë‹µë³€ ê°œì„  ë…¸ë“œ"""
        query = state["query"]
        answer = state["answer"]
        search_results = state["search_results"]

        # ë©”íƒ€ë°ì´í„° ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ ë§í¬ í¬í•¨)
        sources = []
        platforms = set()
        for result in search_results:
            # ì ìˆ˜ ê¸°ì¤€ì„ ë‚®ì¶¤ (0.8 -> 0.55) ê·¸ë¦¬ê³  ìƒìœ„ 5ê°œë§Œ í¬í•¨
            if result['score'] > 0.55 and len(sources) < 5:  # ì ìˆ˜ ê¸°ì¤€ ë‚®ì¶”ê³  ê°œìˆ˜ ì œí•œ
                source_info = {
                    'title': result['title'],
                    'url': result['url'],
                    'platform': result['platform'],
                    'score': result['score']
                }

                # íƒ€ì„ìŠ¤íƒ¬í”„ URL ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
                if 'timestamp_url' in result and result['timestamp_url']:
                    source_info['timestamp_url'] = result['timestamp_url']
                    # ì‹œê°„ ì •ë³´ ì¶”ê°€
                    if 'start_time' in result and result['start_time'] is not None:
                        minutes = int(result['start_time']) // 60
                        seconds = int(result['start_time']) % 60
                        source_info['timestamp'] = f"{minutes}:{seconds:02d}"

                sources.append(source_info)
                platforms.add(result['platform'])

        state["metadata"] = {
            "sources": sources,
            "platforms": list(platforms),
            "search_count": len(search_results),
            "high_score_count": len([r for r in search_results if r['score'] > 0.8])
        }

        # ì°¸ê³  ìë£Œë¥¼ ë‹µë³€ì— ì¶”ê°€
        if sources:
            references = "\n\n### ğŸ“š ì°¸ê³  ìë£Œ\n"
            for i, source in enumerate(sources, 1):
                # íƒ€ì„ìŠ¤íƒ¬í”„ URLì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                link_url = source.get('timestamp_url', source.get('url', ''))
                timestamp = source.get('timestamp', '')

                if timestamp:
                    references += f"{i}. [{source['title']}]({link_url}) - {timestamp}\n"
                else:
                    references += f"{i}. [{source['title']}]({link_url})\n"

            state["answer"] = state["answer"] + references

        return state

    def search_similar_content(
        self,
        query: str,
        filters: Dict = None,
        limit: int = 10
    ) -> List[Dict]:
        """ìœ ì‚¬ ì½˜í…ì¸  ê²€ìƒ‰"""
        query_embedding = self._get_embeddings([query])[0]

        # í•„í„° êµ¬ì„±
        search_filter = None
        if filters:
            conditions = []
            if filters.get('platform'):
                conditions.append(
                    FieldCondition(
                        key="platform",
                        match=MatchValue(value=filters['platform'])
                    )
                )
            if filters.get('language'):
                conditions.append(
                    FieldCondition(
                        key="language",
                        match=MatchValue(value=filters['language'])
                    )
                )

            if conditions:
                search_filter = Filter(must=conditions)

        # ê²€ìƒ‰ ìˆ˜í–‰
        results = self.qdrant_client.search(
            collection_name="youtube_content",
            query_vector=query_embedding,
            query_filter=search_filter,
            limit=limit,
            score_threshold=0.5
        )

        # ê²°ê³¼ ì •ë¦¬
        processed_results = []
        for result in results:
            payload = result.payload
            processed_results.append({
                'id': result.id,
                'score': result.score,
                'content': payload.get('text', ''),
                'title': payload.get('title', ''),
                'url': payload.get('url', ''),
                'platform': payload.get('platform', ''),
                'publish_date': payload.get('publish_date', ''),
                'metadata': payload
            })

        return processed_results

    def ask(self, query: str, filters: Dict = None) -> Dict:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        print(f"[Ask] Query received: {query}")

        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = {
            "messages": [],
            "query": query,
            "search_results": [],
            "context": "",
            "answer": "",
            "metadata": {}
        }

        # í•„í„°ê°€ ìˆìœ¼ë©´ ê²€ìƒ‰ì— ì ìš© (í–¥í›„ í™•ì¥ì„ ìœ„í•´ ì¶”ê°€)
        if filters:
            initial_state["filters"] = filters

        # ê·¸ë˜í”„ ì‹¤í–‰
        print(f"[Ask] Invoking graph with state...")
        result = self.graph.invoke(initial_state)
        print(f"[Ask] Graph execution complete. Found {len(result.get('search_results', []))} results")

        return {
            "query": query,
            "answer": result["answer"],
            "sources": result["metadata"].get("sources", []),
            "platforms": result["metadata"].get("platforms", []),
            "search_stats": {
                "total_results": result["metadata"].get("search_count", 0),
                "high_score_results": result["metadata"].get("high_score_count", 0)
            }
        }

    def get_trending_topics(self, platform: str = None, limit: int = 10) -> List[Dict]:
        """ì¸ê¸° í† í”½ ì¡°íšŒ (ìµœê·¼ ì½˜í…ì¸  ê¸°ë°˜)"""
        # ê°„ë‹¨í•œ êµ¬í˜„: ìµœê·¼ ë²¡í„°ë“¤ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ê¸° í† í”½ ì¶”ì¶œ
        # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¶„ì„ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ

        search_filter = None
        if platform:
            search_filter = Filter(
                must=[
                    FieldCondition(
                        key="platform",
                        match=MatchValue(value=platform)
                    )
                ]
            )

        # ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ìµœê·¼ ì½˜í…ì¸  ì¡°íšŒ
        results = self.qdrant_client.search(
            collection_name="youtube_content",
            query_vector=[0.0] * 1536,  # ë”ë¯¸ ë²¡í„°
            query_filter=search_filter,
            limit=limit * 2
        )

        # ì œëª©ë³„ ê·¸ë£¹í™” ë° ì •ë¦¬
        topics = {}
        for result in results:
            payload = result.payload
            title = payload.get('title', '')
            if title and title not in topics:
                topics[title] = {
                    'title': title,
                    'url': payload.get('url', ''),
                    'platform': payload.get('platform', ''),
                    'publish_date': payload.get('publish_date', ''),
                    'preview': payload.get('chunk_text', '')[:200] + '...'
                }

        return list(topics.values())[:limit]