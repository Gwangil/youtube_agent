#!/usr/bin/env python3
"""
ì„ë² ë”© ì„œë¹™ ì„œë²„
Whisper ì„œë²„ì²˜ëŸ¼ ì¤‘ì•™ì§‘ì¤‘ì‹ ì„ë² ë”© ì²˜ë¦¬
OpenAI API ë˜ëŠ” BGE-M3 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 1024ì°¨ì› ì„ë² ë”© ì œê³µ
"""

import os
import sys
import time
import torch
import hashlib
import logging
from typing import List, Dict, Optional
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from contextlib import asynccontextmanager
import uvicorn

# Add project root to path
sys.path.append('/app')
sys.path.append('/app/shared')

from shared.utils.embeddings import HybridEmbeddings

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì „ì—­ ì„ë² ë”© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
embedding_model = None
model_info = {}


class EmbeddingRequest(BaseModel):
    """ì„ë² ë”© ìš”ì²­ ëª¨ë¸"""
    texts: List[str]
    batch_size: Optional[int] = 32


class EmbeddingResponse(BaseModel):
    """ì„ë² ë”© ì‘ë‹µ ëª¨ë¸"""
    embeddings: List[List[float]]
    dimension: int
    model_info: dict
    processing_time: float


class SingleEmbeddingRequest(BaseModel):
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”© ìš”ì²­"""
    text: str


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    global embedding_model, model_info

    # ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ
    logger.info("ğŸš€ ì„ë² ë”© ì„œë²„ ì´ˆê¸°í™” ì¤‘...")

    try:
        # HybridEmbeddings ì´ˆê¸°í™” (OpenAI API ìš°ì„ , BGE-M3 í´ë°±)
        embedding_model = HybridEmbeddings(prefer_local=False)  # API ìš°ì„ 
        model_info = embedding_model.get_model_info()

        logger.info(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        logger.info(f"  ğŸ“Š ëª¨ë¸: {model_info['model_name']}")
        logger.info(f"  ğŸ¯ íƒ€ì…: {model_info['model_type']}")
        logger.info(f"  ğŸ“ ì°¨ì›: {model_info.get('dimension', 1024)}")
        logger.info(f"  ğŸ’» ë””ë°”ì´ìŠ¤: {model_info['device']}")

        # í…ŒìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
        test_texts = ["í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤."]
        test_embeddings = embedding_model.embed_documents(test_texts)
        actual_dim = len(test_embeddings[0])
        model_info['actual_dimension'] = actual_dim
        logger.info(f"  âœ… ì‹¤ì œ ì„ë² ë”© ì°¨ì› í™•ì¸: {actual_dim}")

    except Exception as e:
        logger.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

    yield  # ì„œë²„ ì‹¤í–‰

    # ì¢…ë£Œ ì‹œ ì •ë¦¬
    logger.info("ğŸ›‘ ì„ë² ë”© ì„œë²„ ì¢…ë£Œ")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Embedding Server",
    description="ì¤‘ì•™ì§‘ì¤‘ì‹ ì„ë² ë”© ì²˜ë¦¬ ì„œë²„",
    version="1.0.0",
    lifespan=lifespan
)


@app.get("/")
async def root():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "service": "Embedding Server",
        "status": "running",
        "model_info": model_info
    }


@app.get("/health")
async def health():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    if embedding_model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")

    return {
        "status": "healthy",
        "model": model_info.get('model_name', 'unknown'),
        "type": model_info.get('model_type', 'unknown'),
        "dimension": model_info.get('actual_dimension', model_info.get('dimension', 1024)),
        "device": model_info.get('device', 'unknown')
    }


@app.post("/embed", response_model=EmbeddingResponse)
async def embed_texts(request: EmbeddingRequest):
    """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    if embedding_model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")

    if not request.texts:
        raise HTTPException(status_code=400, detail="No texts provided")

    try:
        start_time = time.time()

        # ì„ë² ë”© ìƒì„±
        logger.info(f"ğŸ“ {len(request.texts)}ê°œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìš”ì²­")
        embeddings = embedding_model.embed_documents(request.texts)

        processing_time = time.time() - start_time

        # ì‹¤ì œ ì°¨ì› í™•ì¸
        actual_dim = len(embeddings[0]) if embeddings else 0

        logger.info(f"âœ… ì„ë² ë”© ì™„ë£Œ: {len(embeddings)}ê°œ, {actual_dim}ì°¨ì›, {processing_time:.2f}ì´ˆ")

        return EmbeddingResponse(
            embeddings=embeddings,
            dimension=actual_dim,
            model_info={
                "model_name": model_info.get('model_name'),
                "model_type": model_info.get('model_type'),
                "processing_time": processing_time
            },
            processing_time=processing_time
        )

    except Exception as e:
        logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Embedding failed: {str(e)}")


@app.post("/embed_query")
async def embed_query(request: SingleEmbeddingRequest):
    """ë‹¨ì¼ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    if embedding_model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")

    if not request.text:
        raise HTTPException(status_code=400, detail="No text provided")

    try:
        start_time = time.time()

        # ì„ë² ë”© ìƒì„±
        embedding = embedding_model.embed_query(request.text)

        processing_time = time.time() - start_time

        return {
            "embedding": embedding,
            "dimension": len(embedding),
            "processing_time": processing_time
        }

    except Exception as e:
        logger.error(f"ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Query embedding failed: {str(e)}")


@app.get("/model_info")
async def get_model_info():
    """í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
    if embedding_model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")

    return {
        **model_info,
        "actual_dimension": model_info.get('actual_dimension', 1024)
    }


@app.post("/benchmark")
async def benchmark():
    """ì„ë² ë”© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    if embedding_model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")

    try:
        test_texts = [
            "ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤.",
            "The quick brown fox jumps over the lazy dog.",
            "í•œêµ­ì–´ì™€ ì˜ì–´ë¥¼ ëª¨ë‘ í¬í•¨í•œ ë¬¸ì¥ì…ë‹ˆë‹¤.",
            "ì„ë² ë”© ì„œë²„ì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ëŠ” ì²˜ë¦¬ ì‹œê°„ê³¼ ì°¨ì›ì„ í¬í•¨í•©ë‹ˆë‹¤."
        ] * 10  # 50ê°œ ë¬¸ì¥

        start_time = time.time()
        embeddings = embedding_model.embed_documents(test_texts)
        processing_time = time.time() - start_time

        return {
            "num_texts": len(test_texts),
            "total_time": processing_time,
            "avg_time_per_text": processing_time / len(test_texts),
            "texts_per_second": len(test_texts) / processing_time,
            "embedding_dimension": len(embeddings[0]) if embeddings else 0,
            "model_info": model_info
        }

    except Exception as e:
        logger.error(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Benchmark failed: {str(e)}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    port = int(os.getenv('EMBEDDING_SERVER_PORT', '8083'))
    host = os.getenv('EMBEDDING_SERVER_HOST', '0.0.0.0')

    logger.info(f"ğŸš€ ì„ë² ë”© ì„œë²„ ì‹œì‘: {host}:{port}")

    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level="info"
    )


if __name__ == "__main__":
    main()