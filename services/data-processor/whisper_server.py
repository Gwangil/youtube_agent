#!/usr/bin/env python3
"""
Whisper STT ì „ìš© ì„œë¹™ ì„œë²„
GPU/CPU ìë™ ê°ì§€ ë° ëª¨ë¸ í¬ê¸° ìµœì í™”
"""

import os
import sys
import json
import re
import tempfile
import torch
import whisper
from datetime import datetime
from fastapi import FastAPI, HTTPException, File, UploadFile, Form
from pydantic import BaseModel
from typing import Optional, List, Dict
import uvicorn

app = FastAPI(title="Whisper STT Server")

class STTRequest(BaseModel):
    audio_path: str
    language: Optional[str] = "ko"

class STTResponse(BaseModel):
    segments: List[Dict]
    language: str
    model_info: Dict


class WhisperServer:
    def __init__(self):
        self.device_info = self._get_device_info()
        self.model_name = self._select_optimal_model()
        self.model = None
        self._load_model()

        print(f"ğŸ™ï¸ Whisper ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  ë””ë°”ì´ìŠ¤: {self.device_info['type']} ({self.device_info['name']})")
        print(f"  ëª¨ë¸: {self.model_name}")
        if self.device_info['type'] == 'cuda':
            print(f"  VRAM: {self.device_info['memory']:.1f}GB")

    def _get_device_info(self) -> Dict:
        """GPU/CPU ë””ë°”ì´ìŠ¤ ì •ë³´ ì¡°íšŒ"""
        device_info = {"type": "cpu", "name": "CPU", "memory": 0}

        if torch.cuda.is_available():
            device_info["type"] = "cuda"
            device_info["name"] = torch.cuda.get_device_name(0)
            device_info["memory"] = torch.cuda.get_device_properties(0).total_memory / 1024**3

        return device_info

    def _select_optimal_model(self) -> str:
        """ë””ë°”ì´ìŠ¤ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì„ íƒ"""
        if self.device_info["type"] == "cuda":
            # GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ VRAMì— ë”°ë¼ ëª¨ë¸ ì„ íƒ
            vram_gb = self.device_info["memory"]
            if vram_gb >= 8:
                return "large-v3"  # ~3GB VRAM ì‚¬ìš© (ìµœì‹  ë²„ì „)
            elif vram_gb >= 4:
                return "medium"  # ~1.5GB VRAM ì‚¬ìš©
            else:
                return "base"   # ~0.5GB VRAM ì‚¬ìš©
        else:
            # CPU ëª¨ë“œ: ì†ë„ ìš°ì„ ìœ¼ë¡œ ì‘ì€ ëª¨ë¸ ì„ íƒ
            return "base"  # ê°€ì¥ ë¹ ë¥¸ ì²˜ë¦¬

    def _load_model(self):
        """ëª¨ë¸ ë¡œë”©"""
        try:
            print(f"ğŸ”„ Whisper {self.model_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
            start_time = datetime.now()

            device = self.device_info["type"]

            # Whisper ìºì‹œ ë””ë ‰í† ë¦¬ë¥¼ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •
            os.environ['TORCH_HOME'] = '/app/models'

            # ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ í™•ì¸
            model_mapping = {
                "large-v3": "/app/models/whisper/large-v3.pt",
                "large": "/app/models/whisper/large.pt",
                "medium": "/app/models/whisper/medium.pt",
                "base": "/app/models/whisper/base.pt",
            }

            local_model_path = model_mapping.get(self.model_name)

            if local_model_path and os.path.exists(local_model_path):
                print(f"  ğŸ“‚ ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©: {local_model_path}")

                # ì§ì ‘ torch.loadë¡œ ëª¨ë¸ ë¡œë“œ ì‹œë„
                try:
                    import torch
                    # ëª¨ë¸ íŒŒì¼ ì§ì ‘ ë¡œë“œ
                    print(f"  ğŸ”§ ëª¨ë¸ íŒŒì¼ ì§ì ‘ ë¡œë“œ ì¤‘...")

                    # Whisper load_modelì„ download_rootì™€ í•¨ê»˜ ì‚¬ìš©
                    self.model = whisper.load_model(
                        name=self.model_name,
                        device=device,
                        download_root="/app/models/whisper",
                        in_memory=True  # ë©”ëª¨ë¦¬ì— ì§ì ‘ ë¡œë“œ
                    )
                    print(f"  âœ… ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                except Exception as load_error:
                    print(f"  âš ï¸ ì§ì ‘ ë¡œë“œ ì‹¤íŒ¨: {load_error}")
                    # í´ë°±: ìºì‹œ ë””ë ‰í† ë¦¬ ë³µì‚¬ ë°©ì‹
                    cache_dir = os.path.expanduser("~/.cache/whisper")
                    os.makedirs(cache_dir, exist_ok=True)

                    # íŒŒì¼ëª… ë§¤í•‘ (Whisperê°€ ê¸°ëŒ€í•˜ëŠ” í•´ì‹œ)
                    hash_mapping = {
                        "large-v3": "large-v3.pt",  # ì§ì ‘ íŒŒì¼ëª… ì‚¬ìš©
                        "large": "large-v2.pt",
                        "medium": "medium.pt",
                        "base": "base.pt",
                    }

                    cache_filename = hash_mapping.get(self.model_name, f"{self.model_name}.pt")
                    cache_path = os.path.join(cache_dir, cache_filename)

                    if not os.path.exists(cache_path):
                        import shutil
                        print(f"  ğŸ“‹ ëª¨ë¸ì„ ìºì‹œë¡œ ë³µì‚¬: {cache_path}")
                        shutil.copy2(local_model_path, cache_path)

                    # ëª¨ë¸ ë¡œë“œ
                    self.model = whisper.load_model(
                        self.model_name,
                        device=device
                    )
            else:
                print(f"  âš ï¸ ë¡œì»¬ ëª¨ë¸ ì—†ìŒ, ì˜¨ë¼ì¸ì—ì„œ ë‹¤ìš´ë¡œë“œ")
                self.model = whisper.load_model(
                    self.model_name,
                    device=device,
                    download_root="/app/models/whisper"
                )

            load_time = (datetime.now() - start_time).total_seconds()
            print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ ({load_time:.1f}ì´ˆ)")

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

            # í´ë°±: ë” ì‘ì€ ëª¨ë¸ë¡œ ì¬ì‹œë„
            if self.model_name != "tiny":
                fallback_models = {"large-v3": "large", "large": "medium", "medium": "base", "base": "tiny"}
                self.model_name = fallback_models.get(self.model_name, "tiny")
                print(f"ğŸ”„ í´ë°± ëª¨ë¸ë¡œ ì¬ì‹œë„: {self.model_name}")
                self._load_model()
            else:
                raise

    def _clean_repetitive_text(self, text: str) -> str:
        """ë°˜ë³µë˜ëŠ” í…ìŠ¤íŠ¸ íŒ¨í„´ ì œê±°"""
        if not text:
            return text

        # ì—°ì†ëœ ë™ì¼ ë‹¨ì–´ ì œê±° (ì˜ˆ: "ì•ˆë…• ì•ˆë…• ì•ˆë…•" -> "ì•ˆë…•")
        text = re.sub(r'\b(\w+)(\s+\1\b)+', r'\1', text)

        # ì—°ì†ëœ ë™ì¼ êµ¬ë¬¸ ì œê±° (ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš” ì•ˆë…•í•˜ì„¸ìš”" -> "ì•ˆë…•í•˜ì„¸ìš”")
        words = text.split()
        if len(words) < 4:
            return text

        cleaned_words = []
        i = 0
        while i < len(words):
            # 2-gramë¶€í„° 5-gramê¹Œì§€ ë°˜ë³µ íŒ¨í„´ ì²´í¬
            max_pattern_length = min(5, (len(words) - i) // 2)
            pattern_found = False

            for pattern_len in range(max_pattern_length, 1, -1):
                if i + pattern_len * 2 <= len(words):
                    pattern = words[i:i+pattern_len]
                    next_pattern = words[i+pattern_len:i+pattern_len*2]

                    if pattern == next_pattern:
                        # íŒ¨í„´ ë°œê²¬ - í•œ ë²ˆë§Œ ì¶”ê°€í•˜ê³  ëª¨ë“  ë°˜ë³µ ê±´ë„ˆë›°ê¸°
                        cleaned_words.extend(pattern)
                        # ì—°ì†ëœ ëª¨ë“  ë°˜ë³µì„ ì°¾ì•„ì„œ ì œê±°
                        j = i + pattern_len * 2
                        while j + pattern_len <= len(words):
                            if words[j:j+pattern_len] == pattern:
                                j += pattern_len
                            else:
                                break
                        i = j
                        pattern_found = True
                        break

            if not pattern_found:
                cleaned_words.append(words[i])
                i += 1

        return ' '.join(cleaned_words)

    def _remove_repetitive_segments(self, segments: List[Dict]) -> List[Dict]:
        """ë°˜ë³µë˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not segments:
            return segments

        cleaned_segments = []
        prev_text = None
        text_history = set()

        for segment in segments:
            if "text" not in segment:
                continue

            original_text = segment["text"].strip()
            if not original_text:
                continue

            # í…ìŠ¤íŠ¸ ì •ë¦¬
            cleaned_text = self._clean_repetitive_text(original_text)

            # ë¹ˆ í…ìŠ¤íŠ¸ë‚˜ ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ í•„í„°ë§
            if not cleaned_text or len(cleaned_text.strip()) < 3:
                continue

            current_text_lower = cleaned_text.lower()

            # ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ì™€ ì™„ì „íˆ ë™ì¼í•œ ê²½ìš° ì œì™¸
            if prev_text and current_text_lower == prev_text:
                continue

            # ì´ì „ì— ë‚˜ì˜¨ í…ìŠ¤íŠ¸ì™€ ë§¤ìš° ìœ ì‚¬í•œ ê²½ìš° ì œì™¸
            if current_text_lower in text_history:
                continue

            # ìœ ì‚¬ë„ ì²´í¬ (80% ì´ìƒ ìœ ì‚¬í•˜ë©´ ì œì™¸)
            is_similar = False
            for hist_text in text_history:
                if self._similarity_ratio(current_text_lower, hist_text) > 0.8:
                    is_similar = True
                    break

            if is_similar:
                continue

            # ì •ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
            cleaned_segment = segment.copy()
            cleaned_segment["text"] = cleaned_text
            cleaned_segments.append(cleaned_segment)

            # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            prev_text = current_text_lower
            text_history.add(current_text_lower)

            # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
            if len(text_history) > 100:
                text_history.pop()

        print(f"  ğŸ”§ ì„¸ê·¸ë¨¼íŠ¸ ì •ë¦¬: {len(segments)} -> {len(cleaned_segments)}")
        return cleaned_segments

    def _similarity_ratio(self, text1: str, text2: str) -> float:
        """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        if not text1 or not text2:
            return 0.0

        words1 = set(text1.split())
        words2 = set(text2.split())

        if not words1 or not words2:
            return 0.0

        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))

        return intersection / union if union > 0 else 0.0

    def transcribe_audio(self, audio_path: str, language: str = "ko") -> Dict:
        """ì˜¤ë””ì˜¤ íŒŒì¼ STT ì²˜ë¦¬"""
        if not self.model:
            raise Exception("ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            print(f"ğŸ™ï¸ STT ì²˜ë¦¬ ì‹œì‘: {os.path.basename(audio_path)}")
            start_time = datetime.now()

            # Whisper ì²˜ë¦¬ ì˜µì…˜ (ê°•í™”ëœ ë°˜ë³µ ë°©ì§€)
            options = {
                "language": language,
                "beam_size": 1,  # í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€
                "best_of": 1,
                "temperature": (0.0, 0.2, 0.4, 0.6, 0.8),
                "compression_ratio_threshold": 2.0,  # ë°˜ë³µ í…ìŠ¤íŠ¸ ê°ì§€ (ê°•í™”)
                "logprob_threshold": -0.8,  # ë‚®ì€ í’ˆì§ˆ í…ìŠ¤íŠ¸ í•„í„°ë§ (ê°•í™”)
                "no_speech_threshold": 0.7,  # ë¬´ìŒ êµ¬ê°„ ê°ì§€ ê°•í™”
                "condition_on_previous_text": False,
                "initial_prompt": None  # ì‹¤ì œ í…ìŠ¤íŠ¸ì— í¬í•¨ë˜ëŠ” ë¬¸ì œë¡œ ì œê±°
            }

            raw_result = self.model.transcribe(audio_path, **options)

            # ë°˜ë³µ ì œê±° í›„ì²˜ë¦¬
            cleaned_segments = self._remove_repetitive_segments(raw_result["segments"])

            result = {
                "segments": cleaned_segments,
                "language": raw_result["language"]
            }

            process_time = (datetime.now() - start_time).total_seconds()
            print(f"âœ… STT ì²˜ë¦¬ ì™„ë£Œ ({process_time:.1f}ì´ˆ)")

            return {
                "segments": result["segments"],
                "language": result["language"],
                "model_info": {
                    "model_name": self.model_name,
                    "device": self.device_info["type"],
                    "processing_time": process_time
                }
            }

        except Exception as e:
            print(f"âŒ STT ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise


# ì „ì—­ ì„œë²„ ì¸ìŠ¤í„´ìŠ¤
whisper_server = None

@app.on_event("startup")
async def startup_event():
    global whisper_server
    if whisper_server is None:
        whisper_server = WhisperServer()

@app.get("/")
async def root():
    return {
        "service": "Whisper STT Server",
        "model": whisper_server.model_name if whisper_server else "Not loaded",
        "device": whisper_server.device_info if whisper_server else "Unknown",
        "status": "ready" if whisper_server and whisper_server.model else "loading"
    }

@app.get("/health")
async def health_check():
    if not whisper_server or not whisper_server.model:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    return {
        "status": "healthy",
        "model": whisper_server.model_name,
        "device": whisper_server.device_info["type"]
    }

@app.post("/transcribe")
async def transcribe_file(
    audio: UploadFile = File(...),
    language: str = Form("ko")
):
    """íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹ì˜ transcribe ì—”ë“œí¬ì¸íŠ¸"""
    if not whisper_server or not whisper_server.model:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    import tempfile
    temp_audio_path = None

    try:
        # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
            temp_audio_path = tmp_file.name
            content = await audio.read()
            tmp_file.write(content)

        # STT ì²˜ë¦¬
        result = whisper_server.transcribe_audio(temp_audio_path, language)

        # ì‘ë‹µ í˜•ì‹ ë³€í™˜ (stt_workerê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹)
        return {
            "segments": result["segments"],
            "language": result["language"],
            "text": " ".join([s.get("text", "") for s in result["segments"]])
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_audio_path and os.path.exists(temp_audio_path):
            try:
                os.remove(temp_audio_path)
            except:
                pass

@app.post("/transcribe_path", response_model=STTResponse)
async def transcribe_path(request: STTRequest):
    """ê²½ë¡œ ê¸°ë°˜ transcribe ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´ ë°©ì‹)"""
    if not whisper_server or not whisper_server.model:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    if not os.path.exists(request.audio_path):
        raise HTTPException(status_code=404, detail="ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    try:
        result = whisper_server.transcribe_audio(request.audio_path, request.language)
        return STTResponse(**result)

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/model-info")
async def get_model_info():
    if not whisper_server:
        return {"status": "not_initialized"}

    return {
        "model_name": whisper_server.model_name,
        "device_info": whisper_server.device_info,
        "status": "ready" if whisper_server.model else "loading"
    }


if __name__ == "__main__":
    print("ğŸš€ Whisper STT ì„œë²„ ì‹œì‘")
    # ì„œë²„ ì‹œì‘ ì „ì— ëª¨ë¸ ì´ˆê¸°í™”
    print("ğŸ“¦ Whisper ëª¨ë¸ ì‚¬ì „ ì´ˆê¸°í™”...")
    whisper_server = WhisperServer()
    print(f"âœ… Whisper ì„œë²„ ì¤€ë¹„ ì™„ë£Œ: {whisper_server.model_name} ({whisper_server.device_info['type']})")

    uvicorn.run(app, host="0.0.0.0", port=8082)