#!/usr/bin/env python3
"""
í”„ë¡œë•ì…˜ ìˆ˜ì •ì‚¬í•­ ê²€ì¦ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
- ë°˜ë³µ í…ìŠ¤íŠ¸ ì œê±° í…ŒìŠ¤íŠ¸
- ì¤‘ë³µ ê°ì§€ í…ŒìŠ¤íŠ¸
- í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸
"""

import re
import hashlib
import unittest
from unittest.mock import Mock, patch
import sys
import os

# Add project paths
sys.path.append('/mnt/d/workspace/projects/youtube_agent')
sys.path.append('/mnt/d/workspace/projects/youtube_agent/services/data-processor')

class TestRepetitionRemoval(unittest.TestCase):
    """ë°˜ë³µ í…ìŠ¤íŠ¸ ì œê±° í…ŒìŠ¤íŠ¸"""

    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        # Whisper ì„œë²„ì˜ ë°˜ë³µ ì œê±° ë¡œì§ ë³µì‚¬
        self.clean_repetitive_text = self._clean_repetitive_text

    def _clean_repetitive_text(self, text: str) -> str:
        """ë°˜ë³µë˜ëŠ” í…ìŠ¤íŠ¸ íŒ¨í„´ ì œê±°"""
        if not text:
            return text

        # ì—°ì†ëœ ë™ì¼ ë‹¨ì–´ ì œê±°
        text = re.sub(r'\b(\w+)(\s+\1\b)+', r'\1', text)

        # ë™ì¼ êµ¬ë¬¸ ë°˜ë³µ ì œê±°
        words = text.split()
        if len(words) < 4:
            return text

        cleaned_words = []
        i = 0
        while i < len(words):
            max_pattern_length = min(5, (len(words) - i) // 2)
            pattern_found = False

            for pattern_len in range(max_pattern_length, 1, -1):
                if i + pattern_len * 2 <= len(words):
                    pattern = words[i:i+pattern_len]
                    next_pattern = words[i+pattern_len:i+pattern_len*2]

                    if pattern == next_pattern:
                        # ì—°ì†ëœ ë°˜ë³µì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ëª¨ë‘ ì œê±°
                        cleaned_words.extend(pattern)
                        j = i + pattern_len * 2
                        while j + pattern_len <= len(words):
                            if words[j:j+pattern_len] == pattern:
                                j += pattern_len
                            else:
                                break
                        i = j
                        pattern_found = True
                        break

            if not pattern_found:
                cleaned_words.append(words[i])
                i += 1

        return ' '.join(cleaned_words)

    def test_simple_word_repetition(self):
        """ë‹¨ìˆœ ë‹¨ì–´ ë°˜ë³µ ì œê±° í…ŒìŠ¤íŠ¸"""
        input_text = "ì•ˆë…• ì•ˆë…• ì•ˆë…• í•˜ì„¸ìš”"
        expected = "ì•ˆë…• í•˜ì„¸ìš”"
        result = self.clean_repetitive_text(input_text)
        self.assertEqual(result, expected)

    def test_phrase_repetition(self):
        """êµ¬ë¬¸ ë°˜ë³µ ì œê±° í…ŒìŠ¤íŠ¸"""
        input_text = "ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œì— ì´ê²ë‹ˆë‹¤ ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œì— ì´ê²ë‹ˆë‹¤"
        expected = "ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œì— ì´ê²ë‹ˆë‹¤"
        result = self.clean_repetitive_text(input_text)
        self.assertEqual(result, expected)

    def test_multiple_repetitions(self):
        """ë‹¤ì¤‘ ë°˜ë³µ ì œê±° í…ŒìŠ¤íŠ¸"""
        input_text = "ë„¤ ì—¬ëŸ¬ë¶„ ë°˜ê°‘ìŠµë‹ˆë‹¤ ë„¤ ì—¬ëŸ¬ë¶„ ë°˜ê°‘ìŠµë‹ˆë‹¤ ë„¤ ì—¬ëŸ¬ë¶„ ë°˜ê°‘ìŠµë‹ˆë‹¤"
        expected = "ë„¤ ì—¬ëŸ¬ë¶„ ë°˜ê°‘ìŠµë‹ˆë‹¤"
        result = self.clean_repetitive_text(input_text)
        self.assertEqual(result, expected)

    def test_no_repetition(self):
        """ë°˜ë³µì´ ì—†ëŠ” í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸"""
        input_text = "ì´ê²ƒì€ ì •ìƒì ì¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤."
        result = self.clean_repetitive_text(input_text)
        self.assertEqual(result, input_text)

    def test_empty_text(self):
        """ë¹ˆ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸"""
        result = self.clean_repetitive_text("")
        self.assertEqual(result, "")

    def test_korean_repetition(self):
        """í•œêµ­ì–´ ë³µì¡í•œ ë°˜ë³µ íŒ¨í„´ í…ŒìŠ¤íŠ¸"""
        input_text = "ì½”ìŠ¤í”¼ëŠ” 3395 ì½”ìŠ¤í”¼ëŠ” 3395 ì½”ìŠ¤í”¼ëŠ” 3395 ì–´ì œê°€ ê°€ì¥ ë‚®ì„ ìˆ˜ë„ ìˆì–´ìš”"
        expected = "ì½”ìŠ¤í”¼ëŠ” 3395 ì–´ì œê°€ ê°€ì¥ ë‚®ì„ ìˆ˜ë„ ìˆì–´ìš”"
        result = self.clean_repetitive_text(input_text)
        self.assertEqual(result, expected)


class TestDeduplication(unittest.TestCase):
    """ì¤‘ë³µ ê°ì§€ í…ŒìŠ¤íŠ¸"""

    def test_hash_deduplication(self):
        """í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        texts = [
            "ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œì…ë‹ˆë‹¤",
            "ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œì…ë‹ˆë‹¤",  # ì™„ì „ ì¤‘ë³µ
            "ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œì…ë‹ˆë‹¤.",  # êµ¬ë‘ì  ì°¨ì´
            "ë‹¤ë¥¸ ë‚´ìš©ì…ë‹ˆë‹¤"
        ]

        seen_hashes = set()
        unique_texts = []

        for text in texts:
            # êµ¬ë‘ì  ì œê±° í›„ í•´ì‹œ ìƒì„±
            clean_text = re.sub(r'[^\w\s]', '', text.lower())
            text_hash = hashlib.md5(clean_text.encode()).hexdigest()
            if text_hash not in seen_hashes:
                unique_texts.append(text)
                seen_hashes.add(text_hash)

        # êµ¬ë‘ì  ì°¨ì´ëŠ” ë™ì¼í•˜ê²Œ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
        self.assertEqual(len(unique_texts), 2)

    def test_similarity_detection(self):
        """ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        def similarity_ratio(text1: str, text2: str) -> float:
            words1 = set(text1.split())
            words2 = set(text2.split())
            if not words1 or not words2:
                return 0.0
            intersection = len(words1.intersection(words2))
            union = len(words1.union(words2))
            return intersection / union if union > 0 else 0.0

        text1 = "ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œì…ë‹ˆë‹¤"
        text2 = "ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤"  # ìœ ì‚¬
        text3 = "ì™„ì „íˆ ë‹¤ë¥¸ ë‚´ìš©ì…ë‹ˆë‹¤"

        sim1_2 = similarity_ratio(text1, text2)
        sim1_3 = similarity_ratio(text1, text3)

        self.assertGreaterEqual(sim1_2, 0.4)  # ìœ ì‚¬
        self.assertLess(sim1_3, 0.3)     # ë‹¤ë¦„


class TestChunkQuality(unittest.TestCase):
    """ì²­í¬ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""

    def test_chunk_size_limits(self):
        """ì²­í¬ í¬ê¸° ì œí•œ í…ŒìŠ¤íŠ¸"""
        # ì‹œë®¬ë ˆì´ì…˜ëœ ì²­í‚¹ ë¡œì§
        def create_chunk(sentences, max_length=600):
            chunk_text = '. '.join(sentences) + '.'
            return {
                'text': chunk_text,
                'sentence_count': len(sentences),
                'length': len(chunk_text)
            }

        # ê¸´ ë¬¸ì¥ë“¤
        long_sentences = [
            "ì´ê²ƒì€ ë§¤ìš° ê¸´ ë¬¸ì¥ì…ë‹ˆë‹¤ " * 20,
            "ë˜ ë‹¤ë¥¸ ê¸´ ë¬¸ì¥ì…ë‹ˆë‹¤ " * 20
        ]

        chunk = create_chunk(long_sentences)

        # ì²­í¬ê°€ ë„ˆë¬´ í¬ì§€ ì•Šì•„ì•¼ í•¨
        self.assertLessEqual(chunk['sentence_count'], 3)

    def test_minimum_content_quality(self):
        """ìµœì†Œ ì½˜í…ì¸  í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
        # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ì œì™¸ë˜ì–´ì•¼ í•¨
        short_texts = ["ë„¤", "ìŒ", "ì•„", "ì–´"]
        valid_texts = []

        for text in short_texts:
            if len(text.strip()) >= 5:  # ìµœì†Œ ê¸¸ì´ ê¸°ì¤€
                valid_texts.append(text)

        self.assertEqual(len(valid_texts), 0)  # ëª¨ë‘ ì œì™¸ë˜ì–´ì•¼ í•¨


class TestWhisperServerIntegration(unittest.TestCase):
    """Whisper ì„œë²„ í†µí•© í…ŒìŠ¤íŠ¸"""

    @patch('requests.post')
    def test_whisper_server_response(self, mock_post):
        """Whisper ì„œë²„ ì‘ë‹µ í…ŒìŠ¤íŠ¸"""
        # ëª¨ì˜ ì‘ë‹µ ì„¤ì •
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "segments": [
                {"text": "ì •ìƒì ì¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤", "start": 0, "end": 2},
                {"text": "ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ì…ë‹ˆë‹¤", "start": 2, "end": 4}
            ],
            "language": "ko",
            "model_info": {
                "model_name": "large",
                "device": "cuda",
                "processing_time": 10.5
            }
        }
        mock_post.return_value = mock_response

        # ì‹¤ì œ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
        import requests
        response = requests.post("http://test:8082/transcribe", json={
            "audio_path": "/test/audio.wav",
            "language": "ko"
        })

        result = response.json()

        # ì‘ë‹µ êµ¬ì¡° ê²€ì¦
        self.assertIn("segments", result)
        self.assertIn("language", result)
        self.assertIn("model_info", result)
        self.assertEqual(len(result["segments"]), 2)


class TestSystemIntegration(unittest.TestCase):
    """ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_end_to_end_quality(self):
        """ì—”ë“œíˆ¬ì—”ë“œ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
        # ì‹œë®¬ë ˆì´ì…˜ëœ STT ê²°ê³¼ (ë°˜ë³µ í¬í•¨)
        stt_segments = [
            {"text": "ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œì…ë‹ˆë‹¤ ì˜¤ëŠ˜ì˜ ë©”ì¸ ì£¼ì œì…ë‹ˆë‹¤", "start": 0, "end": 5},
            {"text": "ì½”ìŠ¤í”¼ ì´ì•¼ê¸°ë¥¼ í•´ë³´ê² ìŠµë‹ˆë‹¤", "start": 5, "end": 8},
            {"text": "ë„¤ ì—¬ëŸ¬ë¶„ ë°˜ê°‘ìŠµë‹ˆë‹¤ ë„¤ ì—¬ëŸ¬ë¶„ ë°˜ê°‘ìŠµë‹ˆë‹¤", "start": 8, "end": 12}
        ]

        # ë°˜ë³µ ì œê±° ì²˜ë¦¬
        cleaner = TestRepetitionRemoval()
        cleaned_segments = []

        for segment in stt_segments:
            cleaned_text = cleaner._clean_repetitive_text(segment["text"])
            if cleaned_text and len(cleaned_text) > 5:
                cleaned_segments.append({
                    **segment,
                    "text": cleaned_text
                })

        # í’ˆì§ˆ ê²€ì¦
        self.assertEqual(len(cleaned_segments), 3)

        # ê° ì„¸ê·¸ë¨¼íŠ¸ì— ë°˜ë³µì´ ì—†ì–´ì•¼ í•¨
        for segment in cleaned_segments:
            text = segment["text"]
            words = text.split()
            # ë™ì¼í•œ ë‹¨ì–´ê°€ ì—°ì†ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ì§€ ì•Šì•„ì•¼ í•¨
            for i in range(len(words) - 1):
                if words[i] == words[i + 1]:
                    self.fail(f"ì—°ì† ë°˜ë³µ ë°œê²¬: {words[i]} in '{text}'")


def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    test_suite = unittest.TestSuite()

    # í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ë“¤ ì¶”ê°€
    test_classes = [
        TestRepetitionRemoval,
        TestDeduplication,
        TestChunkQuality,
        TestWhisperServerIntegration,
        TestSystemIntegration
    ]

    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)

    return result.wasSuccessful()


if __name__ == "__main__":
    print("ğŸ§ª í”„ë¡œë•ì…˜ ìˆ˜ì •ì‚¬í•­ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)

    success = run_all_tests()

    if success:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ")
    else:
        print("\nâŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        print("ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤")

    print("=" * 50)