#!/usr/bin/env python3
"""
ë°ì´í„° ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
PostgreSQLê³¼ Qdrantì˜ ë°ì´í„°ë¥¼ ì„ íƒì ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
"""

import os
import sys
import time
from datetime import datetime
from typing import Dict, List
import logging

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append('/app')
sys.path.append('/app/shared')

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams
import psycopg2

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataResetter:
    """ë°ì´í„° ì´ˆê¸°í™” í´ë˜ìŠ¤"""

    def __init__(self):
        # PostgreSQL ì—°ê²°
        self.db_url = os.getenv('DATABASE_URL', 'postgresql://youtube_user:youtube_pass@postgres:5432/youtube_agent')
        self.engine = create_engine(self.db_url)
        self.SessionLocal = sessionmaker(bind=self.engine)

        # Qdrant ì—°ê²°
        self.qdrant_url = os.getenv('QDRANT_URL', 'http://qdrant:6333')
        self.qdrant_client = QdrantClient(url=self.qdrant_url)

        self.stats = {
            'deleted': {},
            'preserved': {},
            'errors': []
        }

    def backup_channels(self) -> List[Dict]:
        """ì±„ë„ ì •ë³´ ë°±ì—… (ì´ˆê¸°í™” í›„ ë³µì›ìš©)"""
        channels = []
        with self.SessionLocal() as session:
            try:
                result = session.execute(
                    text("SELECT name, url, platform, category, description, language, is_active FROM channels")
                )
                for row in result:
                    channels.append({
                        'name': row[0],
                        'url': row[1],
                        'platform': row[2],
                        'category': row[3],
                        'description': row[4],
                        'language': row[5],
                        'is_active': row[6]
                    })
                logger.info(f"âœ… {len(channels)}ê°œ ì±„ë„ ì •ë³´ ë°±ì—… ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ ì±„ë„ ë°±ì—… ì‹¤íŒ¨: {e}")
                self.stats['errors'].append(f"ì±„ë„ ë°±ì—… ì‹¤íŒ¨: {e}")

        return channels

    def clear_postgres_data(self, preserve_channels: bool = True):
        """PostgreSQL ë°ì´í„° ì´ˆê¸°í™”"""
        logger.info("\n" + "="*50)
        logger.info("PostgreSQL ë°ì´í„° ì´ˆê¸°í™”")
        logger.info("="*50)

        with self.SessionLocal() as session:
            try:
                # ë°±ì—…í•  ì±„ë„ ì •ë³´
                channels_backup = []
                if preserve_channels:
                    channels_backup = self.backup_channels()

                # í…Œì´ë¸” ì´ˆê¸°í™” ìˆœì„œ (ì™¸ë˜í‚¤ ì˜ì¡´ì„± ê³ ë ¤)
                tables_to_clear = [
                    ('vector_mappings', 'CASCADE'),
                    ('transcripts', 'CASCADE'),
                    ('processing_jobs', 'CASCADE'),
                    ('content', 'CASCADE')
                ]

                if not preserve_channels:
                    tables_to_clear.append(('channels', 'CASCADE'))

                for table, cascade in tables_to_clear:
                    try:
                        # ë ˆì½”ë“œ ìˆ˜ í™•ì¸
                        count_before = session.execute(text(f"SELECT COUNT(*) FROM {table}")).scalar()

                        # í…Œì´ë¸” ì´ˆê¸°í™”
                        session.execute(text(f"TRUNCATE TABLE {table} {cascade}"))
                        session.commit()

                        logger.info(f"  âœ… í…Œì´ë¸” '{table}' ì´ˆê¸°í™” ì™„ë£Œ ({count_before}ê°œ ë ˆì½”ë“œ ì‚­ì œ)")
                        self.stats['deleted'][table] = count_before

                    except Exception as e:
                        logger.error(f"  âŒ í…Œì´ë¸” '{table}' ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                        self.stats['errors'].append(f"í…Œì´ë¸” '{table}' ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                        session.rollback()

                # ì‹œí€€ìŠ¤ ë¦¬ì…‹
                sequences = ['channels_id_seq', 'content_id_seq', 'processing_jobs_id_seq',
                            'transcripts_id_seq', 'vector_mappings_id_seq']

                for seq in sequences:
                    try:
                        if not preserve_channels or seq != 'channels_id_seq':
                            session.execute(text(f"ALTER SEQUENCE {seq} RESTART WITH 1"))
                            logger.info(f"  âœ… ì‹œí€€ìŠ¤ '{seq}' ë¦¬ì…‹")
                    except Exception as e:
                        logger.warning(f"  âš ï¸ ì‹œí€€ìŠ¤ '{seq}' ë¦¬ì…‹ ì‹¤íŒ¨: {e}")

                session.commit()

                # ì±„ë„ ì •ë³´ ë³µì›
                if preserve_channels and channels_backup:
                    logger.info(f"\nì±„ë„ ì •ë³´ ë³µì› ì¤‘...")
                    for channel in channels_backup:
                        session.execute(
                            text("""
                                INSERT INTO channels (name, url, platform, category, description, language, is_active)
                                VALUES (:name, :url, :platform, :category, :description, :language, :is_active)
                                ON CONFLICT (url) DO NOTHING
                            """),
                            channel
                        )
                    session.commit()
                    logger.info(f"  âœ… {len(channels_backup)}ê°œ ì±„ë„ ë³µì› ì™„ë£Œ")
                    self.stats['preserved']['channels'] = len(channels_backup)

            except Exception as e:
                logger.error(f"âŒ PostgreSQL ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.stats['errors'].append(f"PostgreSQL ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                session.rollback()

    def clear_qdrant_data(self, recreate_collection: bool = True):
        """Qdrant ë°ì´í„° ì´ˆê¸°í™”"""
        logger.info("\n" + "="*50)
        logger.info("Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”")
        logger.info("="*50)

        try:
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸
            collections = self.qdrant_client.get_collections()
            collection_names = [c.name for c in collections.collections]

            if 'youtube_content' in collection_names:
                # ë²¡í„° ìˆ˜ í™•ì¸
                collection_info = self.qdrant_client.get_collection('youtube_content')
                vector_count = collection_info.points_count
                logger.info(f"  í˜„ì¬ ë²¡í„° ìˆ˜: {vector_count}ê°œ")

                # ì»¬ë ‰ì…˜ ì‚­ì œ
                self.qdrant_client.delete_collection('youtube_content')
                logger.info(f"  âœ… 'youtube_content' ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ")
                self.stats['deleted']['qdrant_vectors'] = vector_count

                if recreate_collection:
                    # ì»¬ë ‰ì…˜ ì¬ìƒì„±
                    self.qdrant_client.recreate_collection(
                        collection_name='youtube_content',
                        vectors_config=VectorParams(
                            size=1536,  # OpenAI embedding dimension
                            distance=Distance.COSINE
                        )
                    )
                    logger.info(f"  âœ… 'youtube_content' ì»¬ë ‰ì…˜ ì¬ìƒì„± ì™„ë£Œ")
            else:
                logger.info("  â„¹ï¸ 'youtube_content' ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

                if recreate_collection:
                    # ì»¬ë ‰ì…˜ ìƒì„±
                    self.qdrant_client.create_collection(
                        collection_name='youtube_content',
                        vectors_config=VectorParams(
                            size=1536,  # OpenAI embedding dimension
                            distance=Distance.COSINE
                        )
                    )
                    logger.info(f"  âœ… 'youtube_content' ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ Qdrant ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.stats['errors'].append(f"Qdrant ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def clear_redis_cache(self):
        """Redis ìºì‹œ ì´ˆê¸°í™”"""
        logger.info("\n" + "="*50)
        logger.info("Redis ìºì‹œ ì´ˆê¸°í™”")
        logger.info("="*50)

        try:
            import redis
            redis_url = os.getenv('REDIS_URL', 'redis://redis:6379/0')
            r = redis.from_url(redis_url)

            # í‚¤ ìˆ˜ í™•ì¸
            key_count = r.dbsize()
            logger.info(f"  í˜„ì¬ í‚¤ ìˆ˜: {key_count}ê°œ")

            # ëª¨ë“  í‚¤ ì‚­ì œ
            r.flushdb()
            logger.info(f"  âœ… Redis ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")
            self.stats['deleted']['redis_keys'] = key_count

        except Exception as e:
            logger.error(f"âŒ Redis ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.stats['errors'].append(f"Redis ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def clear_temp_files(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        logger.info("\n" + "="*50)
        logger.info("ì„ì‹œ íŒŒì¼ ì •ë¦¬")
        logger.info("="*50)

        temp_dirs = ['/tmp/youtube_downloads', '/tmp/whisper_cache', '/app/data/temp']
        deleted_count = 0

        for temp_dir in temp_dirs:
            if os.path.exists(temp_dir):
                try:
                    import shutil
                    file_count = len(os.listdir(temp_dir))
                    shutil.rmtree(temp_dir)
                    os.makedirs(temp_dir, exist_ok=True)
                    logger.info(f"  âœ… {temp_dir}: {file_count}ê°œ íŒŒì¼ ì‚­ì œ")
                    deleted_count += file_count
                except Exception as e:
                    logger.error(f"  âŒ {temp_dir} ì •ë¦¬ ì‹¤íŒ¨: {e}")
                    self.stats['errors'].append(f"{temp_dir} ì •ë¦¬ ì‹¤íŒ¨: {e}")

        self.stats['deleted']['temp_files'] = deleted_count

    def soft_reset(self):
        """ì†Œí”„íŠ¸ ë¦¬ì…‹ (ì±„ë„ ì •ë³´ ë³´ì¡´, ì½˜í…ì¸ ë§Œ ì´ˆê¸°í™”)"""
        logger.info("\n" + "ğŸ”„ ì†Œí”„íŠ¸ ë¦¬ì…‹ ì‹œì‘ (ì±„ë„ ì •ë³´ ë³´ì¡´)")
        logger.info("="*60)

        self.clear_postgres_data(preserve_channels=True)
        self.clear_qdrant_data(recreate_collection=True)
        self.clear_redis_cache()
        self.clear_temp_files()

    def hard_reset(self):
        """í•˜ë“œ ë¦¬ì…‹ (ëª¨ë“  ë°ì´í„° ì´ˆê¸°í™”)"""
        logger.info("\n" + "âš ï¸ í•˜ë“œ ë¦¬ì…‹ ì‹œì‘ (ëª¨ë“  ë°ì´í„° ì‚­ì œ)")
        logger.info("="*60)

        self.clear_postgres_data(preserve_channels=False)
        self.clear_qdrant_data(recreate_collection=True)
        self.clear_redis_cache()
        self.clear_temp_files()

    def generate_report(self):
        """ì´ˆê¸°í™” ê²°ê³¼ ë³´ê³ ì„œ"""
        logger.info("\n" + "="*60)
        logger.info("ì´ˆê¸°í™” ì™„ë£Œ ë³´ê³ ì„œ")
        logger.info("="*60)

        # ì‚­ì œëœ ë°ì´í„°
        if self.stats['deleted']:
            logger.info("\nâœ… ì‚­ì œëœ ë°ì´í„°:")
            for key, value in self.stats['deleted'].items():
                logger.info(f"  - {key}: {value}ê°œ")

        # ë³´ì¡´ëœ ë°ì´í„°
        if self.stats['preserved']:
            logger.info("\nğŸ’¾ ë³´ì¡´ëœ ë°ì´í„°:")
            for key, value in self.stats['preserved'].items():
                logger.info(f"  - {key}: {value}ê°œ")

        # ì—ëŸ¬
        if self.stats['errors']:
            logger.error("\nâŒ ë°œìƒí•œ ì—ëŸ¬:")
            for error in self.stats['errors']:
                logger.error(f"  - {error}")
        else:
            logger.info("\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        return self.stats


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='ë°ì´í„° ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--mode', choices=['soft', 'hard'], required=True,
                      help='ì´ˆê¸°í™” ëª¨ë“œ ì„ íƒ (soft: ì±„ë„ ë³´ì¡´, hard: ì „ì²´ ì´ˆê¸°í™”)')
    parser.add_argument('--force', action='store_true',
                      help='í™•ì¸ ì—†ì´ ì¦‰ì‹œ ì‹¤í–‰')
    args = parser.parse_args()

    # í™•ì¸ í”„ë¡¬í”„íŠ¸
    if not args.force:
        logger.warning("\n" + "âš ï¸ "*10)
        if args.mode == 'hard':
            logger.warning("í•˜ë“œ ë¦¬ì…‹ì„ ì‹¤í–‰í•˜ë©´ ëª¨ë“  ë°ì´í„°ê°€ ì‚­ì œë©ë‹ˆë‹¤!")
            logger.warning("ì±„ë„ ì •ë³´ë¥¼ í¬í•¨í•œ ëª¨ë“  ë°ì´í„°ê°€ ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œë©ë‹ˆë‹¤.")
        else:
            logger.warning("ì†Œí”„íŠ¸ ë¦¬ì…‹ì„ ì‹¤í–‰í•˜ë©´ ì½˜í…ì¸  ë°ì´í„°ê°€ ì‚­ì œë©ë‹ˆë‹¤!")
            logger.warning("ì±„ë„ ì •ë³´ëŠ” ë³´ì¡´ë˜ì§€ë§Œ ëª¨ë“  ì½˜í…ì¸ ì™€ ì²˜ë¦¬ ë°ì´í„°ê°€ ì‚­ì œë©ë‹ˆë‹¤.")

        logger.warning("âš ï¸ "*10 + "\n")

        response = input("ì •ë§ë¡œ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")
        if response.lower() != 'yes':
            logger.info("ì´ˆê¸°í™”ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            sys.exit(0)

    # ì´ˆê¸°í™” ì‹¤í–‰
    resetter = DataResetter()

    start_time = time.time()

    if args.mode == 'hard':
        resetter.hard_reset()
    else:
        resetter.soft_reset()

    elapsed_time = time.time() - start_time
    report = resetter.generate_report()

    logger.info(f"\nâ±ï¸ ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")

    # ì¢…ë£Œ ì½”ë“œ
    if report['errors']:
        sys.exit(1)
    else:
        sys.exit(0)


if __name__ == "__main__":
    main()