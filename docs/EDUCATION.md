# YouTube Content Agent êµìœ¡ ê°€ì´ë“œ

## ğŸ¯ í•™ìŠµ ëª©í‘œ

ì´ êµìœ¡ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ ì´í•´í•˜ê³  í™œìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤:

1. RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œì˜ ì›ë¦¬ì™€ êµ¬í˜„
2. ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì„¤ê³„ ë° êµ¬í˜„
3. ëŒ€ê·œëª¨ ì½˜í…ì¸  ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
4. AI/ML ëª¨ë¸ í†µí•© ë° ìµœì í™”
5. í”„ë¡œë•ì…˜ ë ˆë²¨ ì‹œìŠ¤í…œ ìš´ì˜

## ğŸ“š ì»¤ë¦¬í˜ëŸ¼

### Module 1: ì‹œìŠ¤í…œ ì´í•´ (2ì‹œê°„)

#### 1.1 í”„ë¡œì íŠ¸ ê°œìš”
- YouTube Content Agentë€?
- í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œ
- í•µì‹¬ ê°€ì¹˜ ì œì•ˆ

#### 1.2 ì•„í‚¤í…ì²˜ ì´í•´
- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ê°œë…
- ê° ì„œë¹„ìŠ¤ì˜ ì—­í• ê³¼ ì±…ì„
- ì„œë¹„ìŠ¤ ê°„ í†µì‹  ë°©ì‹

#### 1.3 ê¸°ìˆ  ìŠ¤íƒ ì†Œê°œ
- Python ìƒíƒœê³„
- Dockerì™€ ì»¨í…Œì´ë„ˆí™”
- AI/ML ë„êµ¬ë“¤ (Whisper, OpenAI, LangChain)

### Module 2: RAG ì‹œìŠ¤í…œ ì‹¬í™” (4ì‹œê°„)

#### 2.1 RAG ê°œë…ê³¼ ì›ë¦¬
```
RAG = Retrieval + Augmented + Generation

1. Retrieval (ê²€ìƒ‰)
   - ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ì—­í• 
   - ì„ë² ë”©ê³¼ ìœ ì‚¬ë„ ê²€ìƒ‰
   - Qdrant í™œìš©ë²•

2. Augmented (ì¦ê°•)
   - ì»¨í…ìŠ¤íŠ¸ ì£¼ì…
   - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
   - ë©”íƒ€ë°ì´í„° í™œìš©

3. Generation (ìƒì„±)
   - LLM í™œìš©
   - ì‘ë‹µ ìƒì„± ì „ëµ
   - í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€
```

#### 2.2 ë²¡í„° ì„ë² ë”© ì´í•´
```python
# ì„ë² ë”© ìƒì„± ì˜ˆì œ
from openai import OpenAI

client = OpenAI()

def create_embedding(text):
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

# ìœ ì‚¬ë„ ê³„ì‚°
def cosine_similarity(vec1, vec2):
    """ë‘ ë²¡í„° ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    import numpy as np
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
```

#### 2.3 ì²­í‚¹ ì „ëµ
```python
# ë¬¸ì¥ ê¸°ë°˜ ì²­í‚¹ êµ¬í˜„
def sentence_based_chunking(text, min_size=300, max_size=800):
    """ë¬¸ì¥ ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²­í‚¹"""
    sentences = text.split('.')
    chunks = []
    current_chunk = ""

    for sentence in sentences:
        if len(current_chunk) + len(sentence) < max_size:
            current_chunk += sentence + "."
        else:
            if len(current_chunk) > min_size:
                chunks.append(current_chunk.strip())
                current_chunk = sentence + "."

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks
```

### Module 3: ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (6ì‹œê°„)

#### 3.1 ë°ì´í„° ìˆ˜ì§‘
```python
# YouTube ë°ì´í„° ìˆ˜ì§‘ ì›Œí¬í”Œë¡œìš°
class YouTubeCollector:
    def collect_channel(self, channel_url):
        """ì±„ë„ì˜ ëª¨ë“  ë¹„ë””ì˜¤ ìˆ˜ì§‘"""
        # 1. ì±„ë„ ì •ë³´ íŒŒì‹±
        channel_info = self.parse_channel(channel_url)

        # 2. ë¹„ë””ì˜¤ ëª©ë¡ ìˆ˜ì§‘
        videos = self.get_video_list(channel_info)

        # 3. ë©”íƒ€ë°ì´í„° ì €ì¥
        for video in videos:
            self.save_metadata(video)
            self.create_processing_job(video)
```

#### 3.2 STT ì²˜ë¦¬
```python
# Whisper STT êµ¬í˜„
import whisper

class WhisperProcessor:
    def __init__(self, model_size="large"):
        self.model = whisper.load_model(model_size)

    def transcribe(self, audio_path):
        """ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        result = self.model.transcribe(
            audio_path,
            language='ko',
            beam_size=1,  # í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€
            temperature=0.0
        )
        return self.clean_text(result['text'])

    def clean_text(self, text):
        """ë°˜ë³µ í…ìŠ¤íŠ¸ ì œê±°"""
        # êµ¬í˜„...
```

#### 3.3 ë²¡í„°í™” í”„ë¡œì„¸ìŠ¤
```python
# ë²¡í„°í™” íŒŒì´í”„ë¼ì¸
class VectorizationPipeline:
    def process(self, content):
        # 1. í…ìŠ¤íŠ¸ ì²­í‚¹
        chunks = self.create_chunks(content.transcript)

        # 2. ê° ì²­í¬ ë²¡í„°í™”
        for chunk in chunks:
            vector = self.create_embedding(chunk.text)

            # 3. ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
            self.store_vector(
                vector=vector,
                text=chunk.text,
                metadata={
                    'content_id': content.id,
                    'timestamp_url': chunk.timestamp_url,
                    'channel': content.channel
                }
            )
```

### Module 4: LangGraph ì›Œí¬í”Œë¡œìš° (4ì‹œê°„)

#### 4.1 LangGraph ê¸°ì´ˆ
```python
from langgraph.graph import StateGraph, State

class AgentState(State):
    query: str
    search_results: list
    answer: str

# ì›Œí¬í”Œë¡œìš° ì •ì˜
workflow = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("search", search_node)
workflow.add_node("generate", generate_node)
workflow.add_node("refine", refine_node)

# ì—£ì§€ ì—°ê²°
workflow.add_edge("search", "generate")
workflow.add_edge("generate", "refine")
```

#### 4.2 ê²€ìƒ‰ ë…¸ë“œ êµ¬í˜„
```python
async def search_node(state: AgentState):
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì½˜í…ì¸  ê²€ìƒ‰"""
    # Qdrant ê²€ìƒ‰
    results = await qdrant_client.search(
        collection_name="youtube_content",
        query_vector=create_embedding(state.query),
        limit=5
    )

    state.search_results = results
    return state
```

#### 4.3 ìƒì„± ë° ê°œì„  ë…¸ë“œ
```python
async def generate_node(state: AgentState):
    """ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
    context = format_context(state.search_results)

    prompt = f"""
    ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:

    ì»¨í…ìŠ¤íŠ¸: {context}
    ì§ˆë¬¸: {state.query}
    """

    state.answer = await llm.generate(prompt)
    return state

async def refine_node(state: AgentState):
    """ë‹µë³€ ê°œì„  ë° ì¶œì²˜ ì¶”ê°€"""
    # íƒ€ì„ìŠ¤íƒ¬í”„ ë§í¬ ì¶”ê°€
    # ë‹µë³€ ê²€ì¦
    # í˜•ì‹ ê°œì„ 
    return state
```

### Module 5: ì‹¤ì „ í”„ë¡œì íŠ¸ (8ì‹œê°„)

#### 5.1 í”„ë¡œì íŠ¸ ì„¤ì •
1. ê°œë°œ í™˜ê²½ êµ¬ì„±
2. Docker ì»¨í…Œì´ë„ˆ ë¹Œë“œ
3. ì„œë¹„ìŠ¤ ì—°ë™ í…ŒìŠ¤íŠ¸

#### 5.2 ì‹¤ì œ ì±„ë„ ì²˜ë¦¬
1. YouTube ì±„ë„ ì„ íƒ
2. ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
3. STT ì²˜ë¦¬ ëª¨ë‹ˆí„°ë§
4. ë²¡í„°í™” ì™„ë£Œ í™•ì¸

#### 5.3 ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
1. OpenWebUI ì„¤ì •
2. ëŒ€í™” í…ŒìŠ¤íŠ¸
3. API í†µí•©

#### 5.4 ì„±ëŠ¥ ìµœì í™”
1. ë°°ì¹˜ ì²˜ë¦¬ ì¡°ì •
2. ìºì‹± ì „ëµ êµ¬í˜„
3. ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

### Module 6: ìš´ì˜ ë° ìœ ì§€ë³´ìˆ˜ (4ì‹œê°„)

#### 6.1 ëª¨ë‹ˆí„°ë§
```python
# í—¬ìŠ¤ì²´í¬ êµ¬í˜„
@app.get("/health")
async def health_check():
    checks = {
        "database": check_database(),
        "qdrant": check_qdrant(),
        "redis": check_redis()
    }
    return {"status": "healthy", "checks": checks}
```

#### 6.2 ë¡œê¹… ë° ë””ë²„ê¹…
```python
import logging

# êµ¬ì¡°í™”ëœ ë¡œê¹…
logger = logging.getLogger(__name__)

def process_content(content_id):
    logger.info("Processing started", extra={
        "content_id": content_id,
        "timestamp": datetime.now()
    })

    try:
        # ì²˜ë¦¬ ë¡œì§
        pass
    except Exception as e:
        logger.error("Processing failed", extra={
            "content_id": content_id,
            "error": str(e)
        })
```

#### 6.3 ë°±ì—… ë° ë³µêµ¬
```bash
# ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
pg_dump -U youtube_user youtube_agent > backup_$DATE.sql
aws s3 cp backup_$DATE.sql s3://backups/
```

## ğŸ“ í‰ê°€ ë° ì¸ì¦

### ì‹¤ìŠµ ê³¼ì œ

#### ê³¼ì œ 1: ì»¤ìŠ¤í…€ ì²­í‚¹ ì•Œê³ ë¦¬ì¦˜
- ì£¼ì œ ê¸°ë°˜ ì²­í‚¹ êµ¬í˜„
- ì„±ëŠ¥ ë¹„êµ ë¶„ì„
- ë¬¸ì„œí™”

#### ê³¼ì œ 2: ìƒˆë¡œìš´ ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€
- Podcast í”Œë«í¼ í†µí•©
- ìˆ˜ì§‘ê¸° êµ¬í˜„
- íŒŒì´í”„ë¼ì¸ í†µí•©

#### ê³¼ì œ 3: ì„±ëŠ¥ ê°œì„ 
- í˜„ì¬ ë³‘ëª© ì§€ì  ì‹ë³„
- ê°œì„  ë°©ì•ˆ êµ¬í˜„
- ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

### í‰ê°€ ê¸°ì¤€
- ì½”ë“œ í’ˆì§ˆ (40%)
- ì‹œìŠ¤í…œ ì´í•´ë„ (30%)
- ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ (20%)
- ë¬¸ì„œí™” (10%)

## ğŸ“– ì¶”ê°€ í•™ìŠµ ìë£Œ

### í•„ë… ìë£Œ
1. [RAG ë…¼ë¬¸](https://arxiv.org/abs/2005.11401) - "Retrieval-Augmented Generation"
2. [Whisper ë…¼ë¬¸](https://arxiv.org/abs/2212.04356) - "Robust Speech Recognition"
3. [LangChain ë¬¸ì„œ](https://python.langchain.com/) - ê³µì‹ ë¬¸ì„œ

### ì¶”ì²œ ë„ì„œ
- "Designing Data-Intensive Applications" - Martin Kleppmann
- "Building Microservices" - Sam Newman
- "Natural Language Processing with Transformers" - Lewis Tunstall

### ì˜¨ë¼ì¸ ì½”ìŠ¤
- Fast.ai - Practical Deep Learning
- Coursera - Natural Language Processing Specialization
- Docker Mastery - Complete Course

## ğŸ† ìˆ˜ë£Œ ê¸°ì¤€

### í•„ìˆ˜ ì™„ë£Œ í•­ëª©
- [ ] ëª¨ë“  ëª¨ë“ˆ í•™ìŠµ ì™„ë£Œ
- [ ] ì‹¤ìŠµ ê³¼ì œ 3ê°œ ì œì¶œ
- [ ] ìµœì¢… í”„ë¡œì íŠ¸ ì™„ì„±
- [ ] ì½”ë“œ ë¦¬ë·° í†µê³¼

### ì¸ì¦ì„œ ë°œê¸‰
- ìˆ˜ë£Œ ê¸°ì¤€ ì¶©ì¡± ì‹œ "YouTube Content Agent Developer" ì¸ì¦ì„œ ë°œê¸‰
- GitHub í”„ë¡œí•„ì— ì¶”ê°€ ê°€ëŠ¥í•œ ë°°ì§€ ì œê³µ

## ğŸ’¬ Q&A ë° ì§€ì›

### í•™ìŠµ ì§€ì›
- Slack ì±„ë„: #youtube-agent-education
- ì˜¤í”¼ìŠ¤ ì•„ì›Œ: ë§¤ì£¼ ìˆ˜ìš”ì¼ 14:00-16:00
- 1:1 ë©˜í† ë§: ì‹ ì²­ì œ

### FAQ

**Q: ì‚¬ì „ ì§€ì‹ì´ ì–¼ë§ˆë‚˜ í•„ìš”í•œê°€ìš”?**
A: Python ì¤‘ê¸‰, Docker ê¸°ì´ˆ, SQL ê¸°ì´ˆ ì§€ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.

**Q: í•™ìŠµ ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?**
A: ì£¼ 10ì‹œê°„ íˆ¬ì ì‹œ ì•½ 3-4ì£¼ ì†Œìš”ë©ë‹ˆë‹¤.

**Q: GPUê°€ ê¼­ í•„ìš”í•œê°€ìš”?**
A: í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ Whisper ì²˜ë¦¬ ì†ë„ë¥¼ ìœ„í•´ ê¶Œì¥ë©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ë¡œë“œë§µ

```mermaid
graph LR
    A[ì‹œì‘] --> B[Module 1: ì‹œìŠ¤í…œ ì´í•´]
    B --> C[Module 2: RAG ì‹¬í™”]
    C --> D[Module 3: íŒŒì´í”„ë¼ì¸]
    D --> E[Module 4: LangGraph]
    E --> F[Module 5: ì‹¤ì „ í”„ë¡œì íŠ¸]
    F --> G[Module 6: ìš´ì˜]
    G --> H[í‰ê°€]
    H --> I[ìˆ˜ë£Œ]
```

---

**ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ì…¨ë‚˜ìš”?**
ì²« ëª¨ë“ˆë¶€í„° ì°¨ê·¼ì°¨ê·¼ ì‹œì‘í•´ë³´ì„¸ìš”. ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì»¤ë®¤ë‹ˆí‹°ì— ë¬¸ì˜í•´ì£¼ì„¸ìš”!